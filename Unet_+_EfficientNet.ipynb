{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzEwR0JD3LTB"
      },
      "source": [
        "# UNet model for image segmentation with EfficientNet encoder.\n",
        "\n",
        "Implemented using tensorflow 2.2.0 with custom train and test step. Original implementation of efficient() is modified to tensorflow 2.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqw3cFCPdnqM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b47a10e8-da28-43a2-91db-35c78b5ee93b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "import collections\n",
        "import math\n",
        "import string\n",
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFw70fFeJp3"
      },
      "source": [
        "BlockArgs = collections.namedtuple('BlockArgs', [\n",
        "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
        "    'expand_ratio', 'id_skip', 'strides', 'se_ratio', 'final_bn'\n",
        "])\n",
        "\n",
        "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
        "\n",
        "\n",
        "CONV_KERNEL_INITIALIZER = {\n",
        "    'class_name': 'VarianceScaling',\n",
        "    'config': {\n",
        "        'scale': 2.0,\n",
        "        'mode': 'fan_out',\n",
        "        # EfficientNet actually uses an untruncated normal distribution for\n",
        "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
        "        # a truncated distribution.\n",
        "        # We decided against a custom initializer for better serializability.\n",
        "        'distribution': 'normal'\n",
        "    }\n",
        "}\n",
        "\n",
        "DENSE_KERNEL_INITIALIZER = {\n",
        "    'class_name': 'VarianceScaling',\n",
        "    'config': {\n",
        "        'scale': 1. / 3.,\n",
        "        'mode': 'fan_out',\n",
        "        'distribution': 'uniform'\n",
        "    }\n",
        "}\n",
        "\n",
        "DEFAULT_BLOCKS_ARGS = [\n",
        "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
        "              expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25,\n",
        "              final_bn=True),\n",
        "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
        "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25,\n",
        "              final_bn=True),\n",
        "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
        "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25,\n",
        "              final_bn=True),\n",
        "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
        "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25,\n",
        "              final_bn=True),\n",
        "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
        "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25,\n",
        "              final_bn=True),\n",
        "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
        "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25,\n",
        "              final_bn=True),\n",
        "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
        "              expand_ratio=6, id_skip=False, strides=[1, 1], se_ratio=0.25,\n",
        "              final_bn=False)\n",
        "\n",
        "]\n",
        "\n",
        "ENCODER_LAYERS = [ 'block2a', 'block3a', 'block4a',  'block6a']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWgHWXDXeNIm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YglG0MRX4XxD"
      },
      "source": [
        "# Squeeze and excitation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoT6SEfQeTzg"
      },
      "source": [
        "class SEBlock(Layer):\n",
        "    \"\"\"Implementation of Squeeze and Excitation network\"\"\"\n",
        "    def __init__(self, name, filters, ratio, kernel_initializer,\n",
        "                    activation=tf.nn.swish):\n",
        "        super(SEBlock, self).__init__(name)\n",
        "\n",
        "        self.squeeze = GlobalAveragePooling2D(name='se_squeeze')\n",
        "        self.reduce = Conv2D(filters * ratio,\n",
        "                                kernel_size=1,\n",
        "                                activation=activation,\n",
        "                                padding='same',\n",
        "                                use_bias=True,\n",
        "                                kernel_initializer=kernel_initializer,\n",
        "                                name='se_reduce')\n",
        "\n",
        "        self.expand = Conv2D(filters,\n",
        "                                kernel_size=1,\n",
        "                                activation='sigmoid',\n",
        "                                padding='same',\n",
        "                                use_bias=True,\n",
        "                                kernel_initializer=kernel_initializer,\n",
        "                                name='se_expand')\n",
        "\n",
        "    def call(self, input):\n",
        "        x = self.squeeze(input)\n",
        "        channels = x.shape[-1]\n",
        "        x = tf.reshape(x, (-1, 1, 1, channels))\n",
        "        x = self.reduce(x)\n",
        "        x = self.expand(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMO5Gff54hgs"
      },
      "source": [
        "# Mobile inverted convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHQO6l2GeY41"
      },
      "source": [
        "class MBConvBlock(Layer):\n",
        "    def __init__(self, block_args, kernel_initializer, drop_rate=None,\n",
        "                 name='', activation=tf.nn.swish):\n",
        "        super(MBConvBlock, self).__init__(name=name)\n",
        "        filters = block_args.input_filters * block_args.expand_ratio\n",
        "        self.block_args = block_args\n",
        "        if block_args.expand_ratio != 1:\n",
        "            self.expand_conv = Conv2D(filters, 1, padding='same',\n",
        "                                        use_bias=False,\n",
        "                                        kernel_initializer=kernel_initializer,\n",
        "                                        name='expand_cov')\n",
        "            self.expand_bn = BatchNormalization(axis=3, name='expand_bn')\n",
        "            self.expand_act = Activation(activation, name='expand_activation')\n",
        "\n",
        "        self.depth_conv = DepthwiseConv2D(block_args.kernel_size,\n",
        "                              strides=block_args.strides,\n",
        "                              padding='same',\n",
        "                              use_bias=False,\n",
        "                              depthwise_initializer=kernel_initializer,\n",
        "                              name='dwconv')\n",
        "        self.depth_bn = BatchNormalization(axis=3, name='bn')\n",
        "        self.depth_act = Activation(activation, name='activation')\n",
        "\n",
        "        if block_args.se_ratio > 0:\n",
        "            self.se_block = SEBlock('se', filters , block_args.se_ratio,\n",
        "                                    kernel_initializer)\n",
        "\n",
        "        self.out_conv = Conv2D(block_args.output_filters, 1,\n",
        "                                padding='same',\n",
        "                                use_bias=False,\n",
        "                                kernel_initializer=kernel_initializer,\n",
        "                                name='project')\n",
        "\n",
        "        self.out_bn =  BatchNormalization(axis=3, name='project_bn')\n",
        "\n",
        "    def call(self, input, training):\n",
        "        x = input\n",
        "        if self.block_args.expand_ratio != 1:\n",
        "            x = self.expand_conv(x)\n",
        "            x = self.expand_bn(x)\n",
        "            x = self.expand_act(x)\n",
        "            enc = x\n",
        "\n",
        "        x = self.depth_conv(x)\n",
        "        x = self.depth_bn(x)\n",
        "        x = self.depth_act(x)\n",
        "\n",
        "        if self.block_args.se_ratio > 0:\n",
        "            se = self.se_block(x)\n",
        "            x = tf.math.multiply(x, se)\n",
        "\n",
        "        x = self.out_conv(x)\n",
        "        if self.block_args.final_bn:\n",
        "          x = self.out_bn(x)\n",
        "\n",
        "        if self.block_args.id_skip and \\\n",
        "              self.block_args.input_filters == self.block_args.output_filters:\n",
        "            x = tf.math.add(x, input)\n",
        "\n",
        "        return x, enc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvgCNXhe4t13"
      },
      "source": [
        "# Encoder EfficientNet\n",
        "\n",
        "Block2a expand, Block3a expand, Block6a expand, Block7a project layers are used as encoder output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpmFfA9HeqZ6"
      },
      "source": [
        "class EfficientNet(Layer):\n",
        "    \"\"\"Implementation of base Efficient net\"\"\"\n",
        "    def __init__(self, width_coefficient,\n",
        "                    depth_coefficient,\n",
        "                    dropout_rate=0.2,\n",
        "                    drop_connect_rate=0.2,\n",
        "                    depth_divisor=8,\n",
        "                    activation=tf.nn.swish,\n",
        "                    blocks_args=DEFAULT_BLOCKS_ARGS,\n",
        "                    encoder_layers=ENCODER_LAYERS,\n",
        "                    layer_name='efficient_net',\n",
        "                    weights='imagenet'):\n",
        "      super(EfficientNet, self).__init__(layer_name)\n",
        "      self.layer_name = layer_name\n",
        "      self.block_args = blocks_args\n",
        "      self.encoder_layers = encoder_layers\n",
        "\n",
        "\n",
        "      #stem\n",
        "      self.stem_conv = Conv2D(self.round_filters(32, width_coefficient, depth_divisor), 3,\n",
        "                              strides=(2,2),\n",
        "                              padding='same',\n",
        "                              use_bias=False,\n",
        "                              kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
        "                              name='stem_conv')\n",
        "      self.stem_bn = BatchNormalization(axis=3, name='stem_bn')\n",
        "      self.stem_act = Activation(activation, name='stem_Activation')\n",
        "\n",
        "      self.mb_blocks = {}\n",
        "      for idx, block_args in enumerate(blocks_args):\n",
        "          block_args = block_args._replace(\n",
        "              input_filters=self.round_filters(block_args.input_filters,\n",
        "                                      width_coefficient, depth_divisor),\n",
        "              output_filters=self.round_filters(block_args.output_filters,\n",
        "                                        width_coefficient, depth_divisor),\n",
        "              num_repeat=self.round_repeats(block_args.num_repeat, depth_coefficient))\n",
        "          self.mb_blocks.update({f'block{idx + 1}a' :\n",
        "                              MBConvBlock(block_args, CONV_KERNEL_INITIALIZER ,\n",
        "                                  drop_rate=None, name=f'block{idx + 1}a')})\n",
        "          if idx < (len(blocks_args) - 1):\n",
        "            for bidx in range((block_args.num_repeat - 1)):\n",
        "                block_prefix = f'block{idx + 1}{string.ascii_lowercase[bidx + 1]}'\n",
        "                block_args = block_args._replace(input_filters=block_args.output_filters,\n",
        "                                                  strides=[1, 1])\n",
        "                self.mb_blocks.update({block_prefix : MBConvBlock(block_args,\n",
        "                                            CONV_KERNEL_INITIALIZER,\n",
        "                                            drop_rate=None, name=block_prefix)})\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, input, training=True):\n",
        "      self.output_layers = []\n",
        "      x = self.stem_conv(input)\n",
        "      x = self.stem_bn(x)\n",
        "      x = self.stem_act(x) # 64 * 64\n",
        "\n",
        "      for key in self.mb_blocks.keys():\n",
        "        block = self.mb_blocks[key]\n",
        "        x, enc = block(x, training)\n",
        "        if key in self.encoder_layers:\n",
        "          self.output_layers.append(enc) # 64, 32, 16, 8, 4\n",
        "\n",
        "      self.output_layers.append(x)\n",
        "      return self.output_layers\n",
        "\n",
        "    def get_config(self):\n",
        "      return {'layer_name': self.layer_name}\n",
        "\n",
        "\n",
        "    def round_filters(self, filters, width_coefficient,\n",
        "                            depth_divisor):\n",
        "      \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
        "      filters *= width_coefficient\n",
        "      new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
        "      new_filters = max(depth_divisor, new_filters)\n",
        "      # Make sure that round down does not go down by more than 10%.\n",
        "      if new_filters < 0.9 * filters:\n",
        "          new_filters += depth_divisor\n",
        "      return int(new_filters)\n",
        "\n",
        "    def round_repeats(self, repeats, depth_coefficient):\n",
        "      return int(math.ceil(depth_coefficient * repeats))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAX4lzX64_bT"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZceHsmkgma7"
      },
      "source": [
        "class DecoderBlock(Layer):\n",
        "    def __init__(self, filters1, filters2, name, kernel_size=3):\n",
        "      super(DecoderBlock, self).__init__(name=name)\n",
        "\n",
        "      self.conv_1 = Conv2D(filters1, kernel_size=1, name='conv_1')\n",
        "      self.bn_1 = BatchNormalization(name='conv_bn_1')\n",
        "      self.act_1 = Activation('relu', name='conv_relu_1')\n",
        "\n",
        "      self.up = Conv2DTranspose(filters1, kernel_size,\n",
        "                      strides=(2, 2), padding='same', name='up')\n",
        "      self.up_bn = BatchNormalization(name='up_bn')\n",
        "      self.up_relu = Activation('relu', name='up_act')\n",
        "\n",
        "      self.conv_2 = Conv2D(filters2, kernel_size=1, name='conv_2')\n",
        "      self.bn_2 = BatchNormalization(name='conv_bn_2')\n",
        "      self.act_2 = Activation('relu', name='conv_relu_2')\n",
        "\n",
        "\n",
        "    def call(self, input):\n",
        "      x = self.conv_1(input)\n",
        "      x = self.bn_1(x)\n",
        "      x = self.act_1(x)\n",
        "\n",
        "      x = self.up(x)\n",
        "      x = self.up_bn(x)\n",
        "      x = self.up_relu(x)\n",
        "\n",
        "      x = self.conv_2(x)\n",
        "      x = self.bn_2(x)\n",
        "      x = self.act_2(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PccpNxBoeyYX"
      },
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, start_filters, name='decoder'):\n",
        "      super(Decoder, self).__init__(name)\n",
        "      name = name\n",
        "\n",
        "      self.decoder4 = DecoderBlock(start_filters * 32,\n",
        "                                      start_filters * 16, name='decoder4', kernel_size=3)\n",
        "      self.decoder3 = DecoderBlock(start_filters * 16,\n",
        "                                      start_filters * 8, name='decoder3', kernel_size=3)\n",
        "      self.decoder2 = DecoderBlock(start_filters * 8,\n",
        "                                      start_filters * 4, name='decoder2', kernel_size=3)\n",
        "      self.decoder1 = DecoderBlock(start_filters * 4,\n",
        "                                      start_filters * 2, name='decoder1', kernel_size=3)\n",
        "\n",
        "\n",
        "    def call(self, encoder):\n",
        "      #e0 - 64, e1 - 32, e2 - 16, e3 - 8, e4 - 4\n",
        "      em, e4, e3, e2, e1 = encoder\n",
        "\n",
        "\n",
        "      d4 = self.decoder4(em) # 8 -> 16\n",
        "      d4 = tf.concat([d4, e4], axis=-1)\n",
        "\n",
        "\n",
        "      d3 = self.decoder3(d4) # 16 -> 32\n",
        "      d3 = tf.concat([d3, e3], axis=-1)\n",
        "\n",
        "      d2 = self.decoder2(d3) # 32 -> 64\n",
        "      d2 = tf.concat([d2, e2], axis=-1)\n",
        "\n",
        "      d1 = self.decoder1(d2) # 64 -> 128\n",
        "      d1 = tf.concat([d1, e1], axis=-1)\n",
        "\n",
        "      return d1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDBLhYn45GbF"
      },
      "source": [
        "# UNet model which uses EfficientNet B5 encoders\n",
        "\n",
        "Used custom train and test step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI_uSE8OfgY_"
      },
      "source": [
        "class UNet(Model):\n",
        "    def __init__(self, name, width_coefficient=1,\n",
        "                                   depth_coefficient=1, num_classes=2):\n",
        "        super(UNet, self).__init__(name=name)\n",
        "        # self.name = name\n",
        "        start_filters = 16\n",
        "        self.backbone = EfficientNet(width_coefficient=width_coefficient,\n",
        "                                     depth_coefficient=depth_coefficient)\n",
        "\n",
        "        self.middle_conv = Conv2D(start_filters * 32, kernel_size=3,\n",
        "                                    padding='same', name='middle_conv')\n",
        "        self.middle_bn = BatchNormalization(axis=3, name='middle_bn')\n",
        "        self.middle_act = Activation('relu', name='middle_activation')\n",
        "\n",
        "        self.decoder = Decoder(start_filters)\n",
        "\n",
        "        self.out_conv = Conv2DTranspose(num_classes, 3, strides=2,\n",
        "                            padding='same', name='out_conv')\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, input, training):\n",
        "        encoders = self.backbone(input)\n",
        "        e1, e2, e3, e4, e5 = encoders\n",
        "\n",
        "        # #middle block\n",
        "        em = self.middle_conv(e5)\n",
        "        em = self.middle_bn(em)\n",
        "        em = self.middle_act(em)\n",
        "\n",
        "        encoders = [em, e4, e3, e2, e1]\n",
        "        mask = self.decoder(encoders)\n",
        "\n",
        "        mask = self.out_conv(mask)\n",
        "\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def compile(self, optimizer, loss_fn, train_loss, test_loss,\n",
        "                    metric):\n",
        "      super(UNet, self).compile(optimizer, metrics=metric)\n",
        "      self.optimizer = optimizer\n",
        "      self.loss_fn = loss_fn\n",
        "\n",
        "      self.train_loss = train_loss\n",
        "      self.test_loss = test_loss\n",
        "\n",
        "\n",
        "    def train_step(self, data):\n",
        "        images, mask = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(images, training=True)\n",
        "            loss = self.loss_fn(mask, predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        self.train_loss(loss)\n",
        "        self.compiled_metrics.update_state(mask, predictions)\n",
        "        mean_iou = self.metrics[0]\n",
        "\n",
        "        return {'loss': self.train_loss.result(), \\\n",
        "                    mean_iou.name: mean_iou.result()}\n",
        "\n",
        "\n",
        "    def test_step(self, data):\n",
        "        images, mask = data\n",
        "\n",
        "        predictions = self(images, training=False)\n",
        "        loss = self.loss_fn(mask, predictions)\n",
        "\n",
        "        self.test_loss(loss)\n",
        "        self.compiled_metrics.update_state(mask, predictions)\n",
        "        mean_iou = self.metrics[0]\n",
        "\n",
        "        return {'loss': self.test_loss.result(), \\\n",
        "                    mean_iou.name: mean_iou.result()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jflAWvo-50e7"
      },
      "source": [
        "# Sample data from tfds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLP3LsfdkvK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8ab36ebc-3cfa-4753-eae2-e854788726c9"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "!pip install -q -U tfds-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 2.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8fZpdyOXZfi"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9hAs0D5XchM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "bbae04c0-dc18-4420-a41c-b524f3470ce3"
      },
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset oxford_iiit_pet/3.2.0 (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incomplete86K88S/oxford_iiit_pet-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incomplete86K88S/oxford_iiit_pet-test.tfrecord\n",
            "\u001b[1mDataset oxford_iiit_pet downloaded and prepared to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cop0JsQ3aCwt"
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BW3vrmxaw20"
      },
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEk12s0Daz0L"
      },
      "source": [
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LXzWyPja61p"
      },
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpWOhdaIa95V"
      },
      "source": [
        "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = dataset['test'].map(load_image_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxOl7UoXbAXO"
      },
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mejSzCDIbChM"
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKIRX0rW6ODi"
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs9j7o-P6DCF"
      },
      "source": [
        "# Build and Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp9pZk69bISe"
      },
      "source": [
        "model = UNet(name='Unet-efficientNet',\n",
        "             width_coefficient=1.6,\n",
        "             depth_coefficient=2.2,\n",
        "             num_classes=3)\n",
        "\n",
        "model.build((1, 128, 128, 3))\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              train_loss=train_loss, test_loss=test_loss,\n",
        "              metric = ['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GOuEXBkhz7Q"
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zepoE4zIBRcR"
      },
      "source": [
        "# Display callback to show the predictions after end of every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9tkpHj1SxjI"
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G8Hnyq2B-kI"
      },
      "source": [
        "# Run the model using keras fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWBnYHgGh4vC"
      },
      "source": [
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv18UU9bYNh_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-veMfE1_4ik"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRkVm5Y1ABwN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}